{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KBMOD Results and Filtering  \n",
    "  \n",
    "This notebook demonstrates the basic functionality for loading and filtering results. KBMOD provides the ability to load results into a ``Results`` data structure and then apply a sequence of filters to those results. It also contains special columns (`psi_curve`, `phi_curve`, and `obs_valid`) and helper functions that can be used to automatically update the scoring metrics like `likelihood`, `flux`, and `obs_count`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Before importing, make sure you have installed kbmod using `pip install .` in the root directory.  Also be sure you are running with python3 and using the correct notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything we will need for this demo\n",
    "from kbmod.results import Results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the results\n",
    "\n",
    "We use the fake result data provided in ``data/fake_results_noisy`` which is generated from 256 x 256 images with multiple fake objects inserted. KBMOD is run with wider than normal filter parameters so as to produce a noisy set of results.\n",
    "\n",
    "The `Results` object behaves like an astropy Table with some additional book keeping to help with filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Results.from_trajectory_file(\"../data/fake_results_noisy/results_DEMO.txt\")\n",
    "print(f\"Loaded {len(results)} results with columns {results.colnames}\")\n",
    "\n",
    "# Turn on filtered result tracking.\n",
    "results.track_filtered = True\n",
    "\n",
    "# Show the top 5 rows\n",
    "print(results[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual rows and columns using the `[]` notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"likelihood\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Results\n",
    "\n",
    "We can sort the results by any of the cols of a ``Results`` in either increasing or decreasing order by operating directly on its table object. By default the items are sorted in increasing order, so we will often want to use `reverse=True` in order to get the results in decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.table.sort(keys=\"obs_count\", reverse=True)\n",
    "print(f\"Top 5 by observation count:\")\n",
    "print(results[0:5])\n",
    "\n",
    "print(f\"\\nBottom 5 by Flux:\")\n",
    "results.table.sort(keys=[\"flux\"], reverse=False)\n",
    "print(results[0:5])\n",
    "\n",
    "# Return to sorted by decreasing likelihood.\n",
    "results.table.sort(keys=[\"likelihood\"], reverse=True)\n",
    "print(results[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Individual Attributes\n",
    "\n",
    "Since the `Results`class stores data as a table, the user can easily extract all of the values for a given attribute of the results. For example we could extract all of the flux values and create a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results[\"flux\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "Using the `filter_rows()` method, you can filter out individual rows based on either their indices or a Boolean mask. In addition to the indices/mask, the `filter_rows()` method allows you to specify and optional label for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all results that have a likelihood < 40.0.\n",
    "mask = results[\"likelihood\"] > 40.0\n",
    "results.filter_rows(mask, \"likelihood\")\n",
    "print(f\"{len(results)} results remaining.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the rows that passed the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Results` object always keeps a count of how many results were filtered at each stage in a dictionary `filtered_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.filtered_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we set ``results.track_filtered = True`` above, the ``Results`` object also keeps each row that was rejected by one of the filters. These rows are indexed by the filter name, allowing the user to determine which rows were removed during which filtering stage. \n",
    "\n",
    "We can use the ``get_filtered`` function to retrieve all the filtered rows for a given filter name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the rows that did not pass filter1.\n",
    "filtered = results.get_filtered(\"likelihood\")\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply multiple filters to the ``Results`` object to progressively rule out more and more candidate trajectories. We can even apply the same filter with different parameters.\n",
    "\n",
    "Next we filter out anything with fewer than 10 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all results with fewer than 10 observations.\n",
    "results.filter_rows(results[\"obs_count\"] >= 10, \"obscount=10\")\n",
    "print(f\"{len(results)} results remaining.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverting filters\n",
    "\n",
    "As long as we have ``track_filtered`` turned on, we can undo any of the filtering steps. This appends the previously filtered results to the end of the list (and thus does not preserve ordering). However we can always re-sort if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.revert_filter(\"likelihood\")\n",
    "print(f\"{len(results)} results remaining.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likleihood columns\n",
    "\n",
    "The default likelihood are taken from the `lh` field of the `Trajectory` object. However we may want to update these by filtering individual time steps, such as when applying clipped sigmaG. `Results` provides the ability to append columns with the psi and phi curves and to update the likelihoods directly from those curves using the `add_psi_phi_data()` function.\n",
    "\n",
    "**NOTE:** It is important to use the `add_psi_phi_data()` function to add or update psi and phi information as it will automatically propogate the changes to other columns.\n",
    "\n",
    "Here we start by creating a random psi curve and a constant phi curve. There must be one curve for each result in the data set and all curves must be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times = 20\n",
    "num_results = len(results)\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "psi_curves = 10.0 + rng.standard_normal((num_results, num_times))  \n",
    "phi_curves = np.full((num_results, num_times), 0.1)\n",
    "\n",
    "results = results.add_psi_phi_data(psi_curves, phi_curves)\n",
    "results[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of psi and phi curves comes from the ability to specify a column `obs_valid` which indicates which time steps of the curves are valid. The `obs_valid` entry is a mask of Booleans the same length as the both the psi and phi curves. Only the valid entries are used in the computation of `flux` and `likelihood`. Notice how marking some of the first results's entries as invalid changes the likelihood, flux, and obs_count columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_valid = np.full((num_results, num_times), True)\n",
    "obs_valid[0, 0:3] = False\n",
    "\n",
    "results = results.add_psi_phi_data(psi_curves, phi_curves, obs_valid)\n",
    "results[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also update the valid observations at a later time using the `update_obs_valid()` function.\n",
    "\n",
    "**NOTE:** It is important to use either the `add_psi_phi_data()` or `update_obs_valid()` functions to change the `obs_valid` data as the will automatically propogate the changes to other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_valid[0, 0:3] = True\n",
    "results = results.update_obs_valid(obs_valid)\n",
    "\n",
    "results[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jeremy's KBMOD",
   "language": "python",
   "name": "kbmod_jk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
