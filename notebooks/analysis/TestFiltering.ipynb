{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb42eb8d-7d55-40d1-9aa4-464968482209",
   "metadata": {},
   "source": [
    "# Benchmark Filtering\n",
    "\n",
    "This notebook is used to compare the effectiveness of different filtering algorithms, including combinations of filtering algorithms. It creates a fake data set, applies a subset of filtering algorithms, and then scores the results. It is meant to be used as an evaluation tool when testing new algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02c346-0ef7-4774-b156-9f38002e7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from kbmod.analysis.plotting import plot_image\n",
    "from kbmod.configuration import SearchConfiguration\n",
    "from kbmod.fake_data.fake_data_creator import create_fake_times, FakeDataSet\n",
    "from kbmod.run_search import SearchRunner\n",
    "from kbmod.trajectory_generator import VelocityGridSearch\n",
    "from kbmod.trajectory_utils import match_trajectory_sets\n",
    "\n",
    "import timeit\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1f651-74d9-41e8-8964-fb70eec938c4",
   "metadata": {},
   "source": [
    "## Define the image parameters\n",
    "\n",
    "We predefine a the parameters that indicate how we will generate the data. Users may want to vary these to determine their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82c6cf-7077-41fb-830e-a44e07ca20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set sizes.  Larger image sizes will mean more potential results found (including noise).\n",
    "num_times = 20\n",
    "width = 100\n",
    "height = 150\n",
    "\n",
    "# Create fake times with 3 observations per night.\n",
    "times = create_fake_times(num_times, t0=60000.0, obs_per_day=3, intra_night_gap=0.04, inter_night_gap=1)\n",
    "\n",
    "# Data characteristics\n",
    "psf_val = 3.0\n",
    "noise_level = 2.0\n",
    "mask_fraction = 0.1  # 10% of pixels are masked\n",
    "artifacts_fraction = 0.001  # 0.1% of pixels contain bright artifacts\n",
    "artifacts_brightness = 250.0  # Mean brightness of artifacts (> trajectory brightness)\n",
    "\n",
    "# Information about the trajectors to insert.\n",
    "num_trjs = 20\n",
    "trj_brightness = 200.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0432b",
   "metadata": {},
   "source": [
    "Use the parameters to create the base data set that we will use for all of the studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e778175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake times with 3 observations per night.\n",
    "times = create_fake_times(num_times, t0=60000.0, obs_per_day=3, intra_night_gap=0.04, inter_night_gap=1)\n",
    "\n",
    "# Create a fake data set.\n",
    "fake_ds = FakeDataSet(\n",
    "    width,\n",
    "    height,\n",
    "    times,\n",
    "    mask_fraction=mask_fraction,\n",
    "    noise_level=noise_level,\n",
    "    psf_val=psf_val,\n",
    "    artifacts_fraction=artifacts_fraction,\n",
    "    artifacts_mean=artifacts_brightness,\n",
    "    artifacts_std=noise_level,\n",
    ")\n",
    "\n",
    "plot_image(fake_ds.stack_py.sci[0], title=\"Fake Image\", show_counts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6499ba2",
   "metadata": {},
   "source": [
    "## Define the search parameters\n",
    "\n",
    "We predefine the parameters that will be used in the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_obs = int(num_times / 2)\n",
    "\n",
    "input_parameters = {\n",
    "    \"cpu_only\": True,\n",
    "    \"do_clustering\": False,\n",
    "    \"generate_psi_phi\": True,\n",
    "    \"gpu_filter\": False,\n",
    "    \"lh_level\": 0.00000001,\n",
    "    \"max_results\": 100_000_000,\n",
    "    \"near_dup_thresh\": 1,\n",
    "    \"num_obs\": min_obs,\n",
    "    \"psf_val\": psf_val,\n",
    "    \"results_per_pixel\": 10,\n",
    "    \"sigmaG_filter\": False,\n",
    "}\n",
    "config = SearchConfiguration.from_dict(input_parameters)\n",
    "\n",
    "trj_generator = VelocityGridSearch(41, 0.0, 20.0, 41, -10.0, 10.0)\n",
    "search = SearchRunner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de4d3b-c731-4cdf-9e6c-7aa015660c63",
   "metadata": {},
   "source": [
    "Define a helper function for determining which results match which inserted fakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f18d51-04e8-4150-9e7d-fcb7ae418396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_match_stats(all_trjs, results, threshold, times):\n",
    "    found_trjs = results.make_trajectory_list()\n",
    "    all_matches = match_trajectory_sets(all_trjs, found_trjs, threshold, times=times)\n",
    "    return np.count_nonzero(all_matches > -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a81cec",
   "metadata": {},
   "source": [
    "We define a helper function that selects the correct filtering function from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kbmod.filters.sigma_g_filter import apply_clipped_sigma_g, SigmaGClipping\n",
    "from kbmod.filters.clustering_filters import apply_clustering\n",
    "\n",
    "def _sigma_g_filter(results, lower=0.25, upper=0.75, sigma=2, clip_negative=True):\n",
    "    \"\"\"Filter results based on the sigmaG value.\"\"\"\n",
    "    sigma_g = SigmaGClipping(lower, upper, sigma, clip_negative)\n",
    "    apply_clipped_sigma_g(sigma_g, results)\n",
    "\n",
    "def _cluster_filter(results, cluster_type=\"all\", cluster_eps=10):\n",
    "    \"\"\"Filter results based on clustering.\"\"\"\n",
    "    global times\n",
    "    cluster_params = {\n",
    "        \"cluster_type\": cluster_type,\n",
    "        \"cluster_eps\": cluster_eps,\n",
    "        \"cluster_v_scale\": 1.0,\n",
    "        \"times\": times,\n",
    "    }\n",
    "    apply_clustering(results, cluster_params)\n",
    "\n",
    "# Create a dictionary mapping from filter names to a tuple of the function and its parameters.\n",
    "filters = {\n",
    "    \"sigma_g_25_75_2\": (_sigma_g_filter, {\"lower\": 0.25, \"upper\": 0.75, \"sigma\": 2}),\n",
    "    \"sigma_g_25_75_3\": (_sigma_g_filter, {\"lower\": 0.25, \"upper\": 0.75, \"sigma\": 3}),\n",
    "    \"sigma_g_10_90_2\": (_sigma_g_filter, {\"lower\": 0.10, \"upper\": 0.90, \"sigma\": 2}),\n",
    "    \"sigma_g_10_90_3\": (_sigma_g_filter, {\"lower\": 0.10, \"upper\": 0.90, \"sigma\": 3}),   \n",
    "}\n",
    "\n",
    "# Add a combination of clustering filters.\n",
    "for cluster_type in [\"position\", \"start_end_position\", \"nn_start_end\", \"nn_start\"]:\n",
    "    for cluster_eps in [1.0, 2.0, 5.0, 10.0, 20.0]:\n",
    "        filter_name = f\"cluster_{cluster_type}_{cluster_eps}\"\n",
    "        filters[filter_name] = (_cluster_filter, {\"cluster_type\": cluster_type, \"cluster_eps\": cluster_eps})\n",
    "\n",
    "all_filters = list(filters.keys())\n",
    "num_filters = len(all_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112f01e-9c46-4454-b0e0-ae982ec36d05",
   "metadata": {},
   "source": [
    "## Run and evaluate filtering algorithms\n",
    "\n",
    "Iterate through the different filtering algorithms along with their threshold parameter. Each of these clustering calls takes a while, so we print out progress markers for each run.\n",
    "\n",
    "**Note:** Timing only uses a single clustering run (instead of the average of a bunch), so it will be noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57717dc5-b827-4ff5-90be-9d48aadbf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10\n",
    "\n",
    "num_res = np.zeros((num_filters, num_iterations))\n",
    "num_matched = np.zeros((num_filters, num_iterations))\n",
    "run_time = np.zeros((num_filters, num_iterations))\n",
    "\n",
    "for itr in range(num_iterations):\n",
    "    print(f\"Iteration {itr + 1} of {num_iterations}\")\n",
    "\n",
    "    # Regenerate the data set.\n",
    "    fake_ds.reset()\n",
    "    all_trjs = fake_ds.insert_random_objects_from_generator(num_trjs, trj_generator, trj_brightness)\n",
    "    results = search.do_core_search(config, fake_ds.stack_py, trj_generator)\n",
    "\n",
    "    for f_idx, filter_name in enumerate(all_filters):\n",
    "        print(f\"  Testing filter: {filter_name}\")\n",
    "        tmp_res = results.copy()\n",
    "\n",
    "        # Apply the filter.\n",
    "        filter_func, filter_params = filters[filter_name]\n",
    "        run_time = timeit.timeit(\n",
    "            f\"{filter_func.__name__}(tmp_res, **filter_params)\", \n",
    "            globals=globals()\n",
    "        )\n",
    "\n",
    "        num_res[f_idx, itr] = len(tmp_res)\n",
    "        num_matched[f_idx, itr] = _compute_match_stats(all_trjs, tmp_res, 5.0, times)\n",
    "        run_time[f_idx, itr] = run_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7938f-ba02-47ae-b1bf-8a3ceac4a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results into a Table for easier analysis.\n",
    "from astropy.table import Table\n",
    "results_table = Table(\n",
    "    data={\n",
    "        \"filter\": all_filters,\n",
    "        \"num_results\": np.mean(num_res, axis=1),\n",
    "        \"num_matched\": np.mean(num_matched, axis=1),\n",
    "        \"run_time\": np.mean(run_time, axis=1),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compute precision and recall for each filter.\n",
    "results_table[\"Precision\"] = results_table[\"num_matched\"] / results_table[\"num_results\"]\n",
    "results_table[\"Recall\"] = results_table[\"num_matched\"] / num_trjs\n",
    "\n",
    "print(results_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kbmod_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
